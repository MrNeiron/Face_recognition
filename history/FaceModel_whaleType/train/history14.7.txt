input_shape = (96, 96, 1)
num_examples = 15
num_folders = 2000
start_folder = 0
batch_size_folder = 8
num_folders_val = 80
start_folder_val = 5000
batch_size_folder_val = 2
epochs = 60
learning_rate = 0.001
l2 = 0.0007
name_history = history/FaceModel_whaleType/train/history14.7.txt
save_model_name = models/FaceModel_whaleType/Model_14.7.h5
dataset_positive = ../Datasets/Faces_dataset/Faces
dataset_negative = ../Datasets/Faces_dataset/Faces
description = dropout=0.5 and more data

all_examples = 62400
train_examples = 60000
test_examples = 2400

	Start time = 14:45
	End time = 19:12
	Spend time = 4:27:12
	Accuracy: 0.8623666665554046, Val Accuracy: 0.7008333295583725, Loss: 0.5121355572938919, Val Loss: 0.889013534039259
Epoch 1/60
		 loss: 1.2574908893108367, acc: 0.5764666665792465, val_loss: 1.073367702960968, val_acc: 0.5
Epoch 2/60
		 loss: 0.8060317876338958, acc: 0.6119833334684371, val_loss: 1.042464929819107, val_acc: 0.5
Epoch 3/60
		 loss: 0.7285991384983063, acc: 0.6278666656017303, val_loss: 1.0967392176389694, val_acc: 0.5
Epoch 4/60
		 loss: 0.699178855895996, acc: 0.6454166668653488, val_loss: 6.327422893047332, val_acc: 0.5
Epoch 5/60
		 loss: 0.6827348053455353, acc: 0.6619166667461396, val_loss: 8.051521301269531, val_acc: 0.5
Epoch 6/60
		 loss: 0.6769079566001892, acc: 0.6685333328247071, val_loss: 8.050697326660156, val_acc: 0.5
Epoch 7/60
		 loss: 0.6689820215702057, acc: 0.6726833326816559, val_loss: 3.8373596489429476, val_acc: 0.5
Epoch 8/60
		 loss: 0.6627425764799117, acc: 0.6817999973297119, val_loss: 8.05398178100586, val_acc: 0.5
Epoch 9/60
		 loss: 0.6596988697052002, acc: 0.6862999994754791, val_loss: 8.054832458496094, val_acc: 0.5
Epoch 10/60
		 loss: 0.6563709617853165, acc: 0.6919666659832001, val_loss: 8.055387496948242, val_acc: 0.5
Epoch 11/60
		 loss: 0.6476874551773071, acc: 0.6958333330154419, val_loss: 8.058752059936523, val_acc: 0.5
Epoch 12/60
		 loss: 0.6498320739269257, acc: 0.6986666679382324, val_loss: 8.060503005981445, val_acc: 0.5
Epoch 13/60
		 loss: 0.6447015211582184, acc: 0.7044333353042602, val_loss: 8.060254096984863, val_acc: 0.5
Epoch 14/60
		 loss: 0.6407165538072586, acc: 0.7093333325386048, val_loss: 4.076747524738312, val_acc: 0.5
Epoch 15/60
		 loss: 0.6364927408695221, acc: 0.7106666667461395, val_loss: 7.151041436195373, val_acc: 0.5
Epoch 16/60
		 loss: 0.6325620874166489, acc: 0.717400000333786, val_loss: 3.942476952075958, val_acc: 0.5
Epoch 17/60
		 loss: 0.6323232859373092, acc: 0.7158166666030884, val_loss: 2.7397824943065645, val_acc: 0.5
Epoch 18/60
		 loss: 0.6265558184385299, acc: 0.7236833329200745, val_loss: 6.028334903717041, val_acc: 0.5
Epoch 19/60
		 loss: 0.625317040681839, acc: 0.7249999997615815, val_loss: 1.5608552426099778, val_acc: 0.5
Epoch 20/60
		 loss: 0.6255103681087494, acc: 0.7276666669845581, val_loss: 1.965348494052887, val_acc: 0.5
Epoch 21/60
		 loss: 0.6208463059663772, acc: 0.7348166651725769, val_loss: 4.316820228099823, val_acc: 0.5
Epoch 22/60
		 loss: 0.6219619864225387, acc: 0.7339333338737488, val_loss: 3.4720674991607665, val_acc: 0.5
Epoch 23/60
		 loss: 0.615865507721901, acc: 0.7396833319664001, val_loss: 8.081759452819824, val_acc: 0.5
Epoch 24/60
		 loss: 0.6128421002626419, acc: 0.7449333338737488, val_loss: 2.5806889295578004, val_acc: 0.5
Epoch 25/60
		 loss: 0.6138370102643966, acc: 0.7433166680335999, val_loss: 5.3383993864059445, val_acc: 0.5
Epoch 26/60
		 loss: 0.6102353354692459, acc: 0.7476666693687439, val_loss: 0.7358043931424618, val_acc: 0.6533333323895931
Epoch 27/60
		 loss: 0.6062247980833053, acc: 0.7520166656970978, val_loss: 0.6680672705173493, val_acc: 0.7116666615009308
Epoch 28/60
		 loss: 0.6066830009222031, acc: 0.7548166663646698, val_loss: 0.6828284502029419, val_acc: 0.7020833365619182
Epoch 29/60
		 loss: 0.5987542781829834, acc: 0.7613833334445953, val_loss: 0.9537860363721847, val_acc: 0.5270833373069763
Epoch 30/60
		 loss: 0.5942921530008316, acc: 0.7666500015258789, val_loss: 0.69470224827528, val_acc: 0.7116666652262211
Epoch 31/60
		 loss: 0.5954547494649887, acc: 0.7666166656017304, val_loss: 0.7047943249344826, val_acc: 0.7066666692495346
Epoch 32/60
		 loss: 0.5882457221746444, acc: 0.7753666656017304, val_loss: 0.7014775019139051, val_acc: 0.7170833319425582
Epoch 33/60
		 loss: 0.5864449034929275, acc: 0.7767833318710328, val_loss: 0.6986489914357662, val_acc: 0.7145833358168602
Epoch 34/60
		 loss: 0.5845453859567642, acc: 0.7821666650772094, val_loss: 0.7139375664293766, val_acc: 0.7087499991059303
Epoch 35/60
		 loss: 0.5782911058664322, acc: 0.7857000010013581, val_loss: 0.7554194442927837, val_acc: 0.7029166638851165
Epoch 36/60
		 loss: 0.5784734839200973, acc: 0.7866999995708466, val_loss: 0.722819272428751, val_acc: 0.7025000020861626
Epoch 37/60
		 loss: 0.5745601092576981, acc: 0.7907333340644837, val_loss: 0.7170430712401867, val_acc: 0.6945833332836628
Epoch 38/60
		 loss: 0.5778990306854248, acc: 0.790066668510437, val_loss: 0.7196680411696434, val_acc: 0.6879166655242444
Epoch 39/60
		 loss: 0.5673704715967178, acc: 0.799366667509079, val_loss: 0.7486963495612144, val_acc: 0.694583335518837
Epoch 40/60
		 loss: 0.5633246158361435, acc: 0.8042166676521302, val_loss: 0.8079858303070069, val_acc: 0.6804166629910469
Epoch 41/60
		 loss: 0.5647689603567123, acc: 0.804383333683014, val_loss: 0.7581505544483662, val_acc: 0.680416664481163
Epoch 42/60
		 loss: 0.5611697199344635, acc: 0.8074499998092651, val_loss: 0.739608259499073, val_acc: 0.7116666659712791
Epoch 43/60
		 loss: 0.554216248869896, acc: 0.8157500007152557, val_loss: 0.7818586818873883, val_acc: 0.6924999982118607
Epoch 44/60
		 loss: 0.5564421900510788, acc: 0.8159500002861023, val_loss: 0.8048364043235778, val_acc: 0.689583332836628
Epoch 45/60
		 loss: 0.5516093825101852, acc: 0.8175166680812835, val_loss: 0.7969583243131637, val_acc: 0.705000002682209
Epoch 46/60
		 loss: 0.551475810289383, acc: 0.822133335351944, val_loss: 0.8053313836455345, val_acc: 0.7095833346247673
Epoch 47/60
		 loss: 0.542942628622055, acc: 0.826216667175293, val_loss: 0.8065290436148643, val_acc: 0.6983333304524422
Epoch 48/60
		 loss: 0.5391385625600815, acc: 0.8289499990940093, val_loss: 0.7994986370205879, val_acc: 0.7083333358168602
Epoch 49/60
		 loss: 0.5397544195652008, acc: 0.8327166640758514, val_loss: 0.8151603139936924, val_acc: 0.697083330899477
Epoch 50/60
		 loss: 0.5341275041103363, acc: 0.8381166670322419, val_loss: 0.8028371438384057, val_acc: 0.7049999997019768
Epoch 51/60
		 loss: 0.5314645159244538, acc: 0.8423000001907348, val_loss: 0.8035835184156894, val_acc: 0.7062500029802322
Epoch 52/60
		 loss: 0.5290835254192352, acc: 0.8428666670322418, val_loss: 0.8100692085921765, val_acc: 0.7100000008940697
Epoch 53/60
		 loss: 0.5288848664760589, acc: 0.8459166669845581, val_loss: 0.8312641270458698, val_acc: 0.7033333346247673
Epoch 54/60
		 loss: 0.5303691784143448, acc: 0.8473166680335998, val_loss: 0.8474116027355194, val_acc: 0.7045833319425583
Epoch 55/60
		 loss: 0.5251648166179657, acc: 0.850050000667572, val_loss: 0.8527899734675884, val_acc: 0.7016666680574417
Epoch 56/60
		 loss: 0.522064221739769, acc: 0.8517499988079071, val_loss: 0.8520265139639378, val_acc: 0.7004166677594185
Epoch 57/60
		 loss: 0.5208219242095947, acc: 0.8539666666984558, val_loss: 0.8809922523796558, val_acc: 0.7016666688024997
Epoch 58/60
		 loss: 0.5165922433137894, acc: 0.859333333492279, val_loss: 0.8458033882081508, val_acc: 0.7091666638851166
Epoch 59/60
		 loss: 0.514844366312027, acc: 0.8594500005245209, val_loss: 0.8643973559141159, val_acc: 0.7066666677594184
Epoch 60/60
		 loss: 0.5121355572938919, acc: 0.8623666665554046, val_loss: 0.889013534039259, val_acc: 0.7008333295583725

-----------------------------------------

input_shape = (96, 96, 1)
num_examples = 15
num_folders = 100
start_folder = 6000
batch_size_folder = 8
num_folders_val = 80
start_folder_val = 5000
batch_size_folder_val = 2
epochs = 1
learning_rate = 0.001
l2 = 0.0007
name_history = history/FaceModel_whaleType/train/history14.7.txt
save_model_name = models/FaceModel_whaleType/Model_14.7.h5
dataset_positive = ../Datasets/Faces_dataset/Faces
dataset_negative = ../Datasets/Faces_dataset/Faces
description = dropout=0.5 and more data

all_examples = 5400
train_examples = 3000
test_examples = 2400

	Start time = 20:2
	End time = 20:3
	Spend time = 0:1:4
	Accuracy: 0.6972222179174423, Val Accuracy: 0.6008333303034306, Loss: 0.8796665370464325, Val Loss: 1.1562420696020126
Epoch 1/1
		 loss: 0.8796665370464325, acc: 0.6972222179174423, val_loss: 1.1562420696020126, val_acc: 0.6008333303034306

-----------------------------------------

input_shape = (96, 96, 1)
num_examples = 15
num_folders = 100
start_folder = 6000
batch_size_folder = 8
num_folders_val = 80
start_folder_val = 5000
batch_size_folder_val = 2
epochs = 1
learning_rate = 0.001
l2 = 0.0007
name_history = history/FaceModel_whaleType/train/history14.7.txt
save_model_name = models/FaceModel_whaleType/Model_14.7.h5
dataset_positive = ../Datasets/Faces_dataset/Faces
dataset_negative = ../Datasets/Faces_dataset/Faces
description = dropout=0.5 and more data

all_examples = 5400
train_examples = 3000
test_examples = 2400

	Start time = 3:55
	End time = 3:55
	Spend time = 0:0:42
	Accuracy: 0.6878472218910853, Val Accuracy: 0.5833333313465119, Loss: 0.8797838737567266, Val Loss: 1.2610415011644363
Epoch 1/1
		 loss: 0.8797838737567266, acc: 0.6878472218910853, val_loss: 1.2610415011644363, val_acc: 0.5833333313465119

-----------------------------------------

